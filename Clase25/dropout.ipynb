{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZo5_1i2cLEP"
   },
   "source": [
    "Thanks to: Sebastian Raschka (sraschka@wisc.edu)\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/andrescastro-itm/IA_ITM_2025-2/blob/main/Clase25/dropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNuz2q66cLEU"
   },
   "source": [
    "# MLP with Dropout "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdDKjghycLEV"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "p9V-RXiJcLEW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "h89-E4qMcLEW"
   },
   "outputs": [],
   "source": [
    "# From local helper files\n",
    "from helper_evaluation import set_all_seeds, set_deterministic\n",
    "from helper_train import train_model\n",
    "from helper_plotting import plot_training_loss, plot_accuracy, show_examples\n",
    "from helper_dataset import get_dataloaders_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILwAFYQgcLEY"
   },
   "source": [
    "## Settings and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1Ny7A52pcLEY"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "BATCH_SIZE = 256\n",
    "NUM_HIDDEN_1 = 75\n",
    "NUM_HIDDEN_2 = 45\n",
    "NUM_EPOCHS = 50\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3InaMdBMcLEZ"
   },
   "outputs": [],
   "source": [
    "set_all_seeds(RANDOM_SEED)\n",
    "# set_deterministic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "W07r4JWpcLEa",
    "metadata": {},
    "outputId": "eeb0ab66-379b-4596-bc2e-4907ec38907a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([256, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([256])\n",
      "Class labels of 10 examples: tensor([4, 5, 8, 9, 9, 4, 9, 9, 3, 9])\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### MNIST DATASET\n",
    "##########################\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_dataloaders_mnist(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_fraction=0.1)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    print('Class labels of 10 examples:', labels[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jomw929KcLEb"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vwntdXGqcLEc"
   },
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_classes, drop_proba, \n",
    "                 num_hidden_1, num_hidden_2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.my_network = torch.nn.Sequential(\n",
    "            # 1st hidden layer\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(num_features, num_hidden_1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(drop_proba),\n",
    "            # 2nd hidden layer\n",
    "            torch.nn.Linear(num_hidden_1, num_hidden_2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(drop_proba),\n",
    "            # output layer\n",
    "            torch.nn.Linear(num_hidden_2, num_classes)\n",
    "        )\n",
    "           \n",
    "    def forward(self, x):\n",
    "        logits = self.my_network(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7Mx_MzZcLEd"
   },
   "source": [
    "## Without Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y1REoRJpcLEd",
    "metadata": {},
    "outputId": "f06ca03b-afdd-427d-fe7d-dbc6b510e8c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/050 | Batch 0000/0210 | Loss: 2.3093\n",
      "Epoch: 001/050 | Batch 0050/0210 | Loss: 1.8443\n",
      "Epoch: 001/050 | Batch 0100/0210 | Loss: 0.7622\n",
      "Epoch: 001/050 | Batch 0150/0210 | Loss: 0.6539\n",
      "Epoch: 001/050 | Batch 0200/0210 | Loss: 0.5036\n",
      "Epoch: 001/050 | Train: 86.56% | Validation: 89.12%\n",
      "Time elapsed: 0.46 min\n",
      "Epoch: 002/050 | Batch 0000/0210 | Loss: 0.4685\n",
      "Epoch: 002/050 | Batch 0050/0210 | Loss: 0.4341\n",
      "Epoch: 002/050 | Batch 0100/0210 | Loss: 0.3330\n",
      "Epoch: 002/050 | Batch 0150/0210 | Loss: 0.3330\n",
      "Epoch: 002/050 | Batch 0200/0210 | Loss: 0.3604\n",
      "Epoch: 002/050 | Train: 90.23% | Validation: 92.15%\n",
      "Time elapsed: 0.95 min\n",
      "Epoch: 003/050 | Batch 0000/0210 | Loss: 0.2568\n",
      "Epoch: 003/050 | Batch 0050/0210 | Loss: 0.2746\n",
      "Epoch: 003/050 | Batch 0100/0210 | Loss: 0.2673\n",
      "Epoch: 003/050 | Batch 0150/0210 | Loss: 0.2206\n",
      "Epoch: 003/050 | Batch 0200/0210 | Loss: 0.3525\n",
      "Epoch: 003/050 | Train: 91.08% | Validation: 92.57%\n",
      "Time elapsed: 1.45 min\n",
      "Epoch: 004/050 | Batch 0000/0210 | Loss: 0.3443\n",
      "Epoch: 004/050 | Batch 0050/0210 | Loss: 0.2957\n",
      "Epoch: 004/050 | Batch 0100/0210 | Loss: 0.2460\n",
      "Epoch: 004/050 | Batch 0150/0210 | Loss: 0.4019\n",
      "Epoch: 004/050 | Batch 0200/0210 | Loss: 0.2618\n",
      "Epoch: 004/050 | Train: 92.86% | Validation: 93.95%\n",
      "Time elapsed: 2.78 min\n",
      "Epoch: 005/050 | Batch 0000/0210 | Loss: 0.3645\n",
      "Epoch: 005/050 | Batch 0050/0210 | Loss: 0.2347\n",
      "Epoch: 005/050 | Batch 0100/0210 | Loss: 0.1946\n",
      "Epoch: 005/050 | Batch 0150/0210 | Loss: 0.1806\n",
      "Epoch: 005/050 | Batch 0200/0210 | Loss: 0.1756\n",
      "Epoch: 005/050 | Train: 93.77% | Validation: 94.60%\n",
      "Time elapsed: 3.70 min\n",
      "Epoch: 006/050 | Batch 0000/0210 | Loss: 0.2481\n",
      "Epoch: 006/050 | Batch 0050/0210 | Loss: 0.1993\n",
      "Epoch: 006/050 | Batch 0100/0210 | Loss: 0.2029\n",
      "Epoch: 006/050 | Batch 0150/0210 | Loss: 0.1524\n",
      "Epoch: 006/050 | Batch 0200/0210 | Loss: 0.2691\n",
      "Epoch: 006/050 | Train: 94.46% | Validation: 95.40%\n",
      "Time elapsed: 4.51 min\n",
      "Epoch: 007/050 | Batch 0000/0210 | Loss: 0.2265\n",
      "Epoch: 007/050 | Batch 0050/0210 | Loss: 0.1759\n",
      "Epoch: 007/050 | Batch 0100/0210 | Loss: 0.1864\n",
      "Epoch: 007/050 | Batch 0150/0210 | Loss: 0.2730\n",
      "Epoch: 007/050 | Batch 0200/0210 | Loss: 0.0877\n",
      "Epoch: 007/050 | Train: 94.87% | Validation: 95.83%\n",
      "Time elapsed: 5.26 min\n",
      "Epoch: 008/050 | Batch 0000/0210 | Loss: 0.2651\n",
      "Epoch: 008/050 | Batch 0050/0210 | Loss: 0.2493\n",
      "Epoch: 008/050 | Batch 0100/0210 | Loss: 0.1756\n",
      "Epoch: 008/050 | Batch 0150/0210 | Loss: 0.1485\n",
      "Epoch: 008/050 | Batch 0200/0210 | Loss: 0.3384\n",
      "Epoch: 008/050 | Train: 95.36% | Validation: 95.95%\n",
      "Time elapsed: 6.14 min\n",
      "Epoch: 009/050 | Batch 0000/0210 | Loss: 0.1526\n",
      "Epoch: 009/050 | Batch 0050/0210 | Loss: 0.1184\n",
      "Epoch: 009/050 | Batch 0100/0210 | Loss: 0.1687\n",
      "Epoch: 009/050 | Batch 0150/0210 | Loss: 0.1286\n",
      "Epoch: 009/050 | Batch 0200/0210 | Loss: 0.1585\n",
      "Epoch: 009/050 | Train: 95.98% | Validation: 96.68%\n",
      "Time elapsed: 6.88 min\n",
      "Epoch: 010/050 | Batch 0000/0210 | Loss: 0.1776\n",
      "Epoch: 010/050 | Batch 0050/0210 | Loss: 0.1243\n",
      "Epoch: 010/050 | Batch 0100/0210 | Loss: 0.0981\n",
      "Epoch: 010/050 | Batch 0150/0210 | Loss: 0.1391\n",
      "Epoch: 010/050 | Batch 0200/0210 | Loss: 0.1377\n",
      "Epoch: 010/050 | Train: 96.16% | Validation: 96.47%\n",
      "Time elapsed: 7.48 min\n",
      "Epoch: 011/050 | Batch 0000/0210 | Loss: 0.1365\n",
      "Epoch: 011/050 | Batch 0050/0210 | Loss: 0.1418\n",
      "Epoch: 011/050 | Batch 0100/0210 | Loss: 0.1089\n",
      "Epoch: 011/050 | Batch 0150/0210 | Loss: 0.1889\n",
      "Epoch: 011/050 | Batch 0200/0210 | Loss: 0.1492\n",
      "Epoch: 011/050 | Train: 96.63% | Validation: 96.97%\n",
      "Time elapsed: 8.12 min\n",
      "Epoch: 012/050 | Batch 0000/0210 | Loss: 0.1347\n",
      "Epoch: 012/050 | Batch 0050/0210 | Loss: 0.1517\n",
      "Epoch: 012/050 | Batch 0100/0210 | Loss: 0.0977\n",
      "Epoch: 012/050 | Batch 0150/0210 | Loss: 0.1293\n",
      "Epoch: 012/050 | Batch 0200/0210 | Loss: 0.1255\n",
      "Epoch: 012/050 | Train: 96.83% | Validation: 96.98%\n",
      "Time elapsed: 8.72 min\n",
      "Epoch: 013/050 | Batch 0000/0210 | Loss: 0.0986\n",
      "Epoch: 013/050 | Batch 0050/0210 | Loss: 0.2251\n",
      "Epoch: 013/050 | Batch 0100/0210 | Loss: 0.1357\n",
      "Epoch: 013/050 | Batch 0150/0210 | Loss: 0.1064\n",
      "Epoch: 013/050 | Batch 0200/0210 | Loss: 0.0937\n",
      "Epoch: 013/050 | Train: 97.05% | Validation: 97.15%\n",
      "Time elapsed: 9.60 min\n",
      "Epoch: 014/050 | Batch 0000/0210 | Loss: 0.0883\n",
      "Epoch: 014/050 | Batch 0050/0210 | Loss: 0.1444\n",
      "Epoch: 014/050 | Batch 0100/0210 | Loss: 0.1085\n",
      "Epoch: 014/050 | Batch 0150/0210 | Loss: 0.1072\n",
      "Epoch: 014/050 | Batch 0200/0210 | Loss: 0.0815\n",
      "Epoch: 014/050 | Train: 97.33% | Validation: 97.32%\n",
      "Time elapsed: 10.33 min\n",
      "Epoch: 015/050 | Batch 0000/0210 | Loss: 0.0818\n",
      "Epoch: 015/050 | Batch 0050/0210 | Loss: 0.0483\n",
      "Epoch: 015/050 | Batch 0100/0210 | Loss: 0.0821\n",
      "Epoch: 015/050 | Batch 0150/0210 | Loss: 0.0941\n",
      "Epoch: 015/050 | Batch 0200/0210 | Loss: 0.0771\n",
      "Epoch: 015/050 | Train: 97.25% | Validation: 97.05%\n",
      "Time elapsed: 11.08 min\n",
      "Epoch: 016/050 | Batch 0000/0210 | Loss: 0.0557\n",
      "Epoch: 016/050 | Batch 0050/0210 | Loss: 0.0609\n",
      "Epoch: 016/050 | Batch 0100/0210 | Loss: 0.0670\n",
      "Epoch: 016/050 | Batch 0150/0210 | Loss: 0.1016\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = MultilayerPerceptron(num_features=28*28,\n",
    "                             num_hidden_1=NUM_HIDDEN_1,\n",
    "                             num_hidden_2=NUM_HIDDEN_2,\n",
    "                             drop_proba=0.0,\n",
    "                             num_classes=10)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "minibatch_loss_list, train_acc_list, valid_acc_list = train_model(\n",
    "    model=model,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    test_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE)\n",
    "\n",
    "plot_training_loss(minibatch_loss_list=minibatch_loss_list,\n",
    "                   num_epochs=NUM_EPOCHS,\n",
    "                   iter_per_epoch=len(train_loader),\n",
    "                   results_dir=None,\n",
    "                   averaging_iterations=20)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plot_accuracy(train_acc_list=train_acc_list,\n",
    "              valid_acc_list=valid_acc_list,\n",
    "              results_dir=None)\n",
    "\n",
    "plt.ylim([80, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9r9WzhvYcLEe"
   },
   "source": [
    "## With 50% Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLt7ASOncLEe",
    "metadata": {},
    "outputId": "75f39868-0d1b-467f-b6c0-71f4f6b00af4"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = MultilayerPerceptron(num_features=28*28,\n",
    "                             num_hidden_1=NUM_HIDDEN_1,\n",
    "                             num_hidden_2=NUM_HIDDEN_2,\n",
    "                             drop_proba=0.5,\n",
    "                             num_classes=10)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "minibatch_loss_list, train_acc_list, valid_acc_list = train_model(\n",
    "    model=model,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    test_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE)\n",
    "\n",
    "plot_training_loss(minibatch_loss_list=minibatch_loss_list,\n",
    "                   num_epochs=NUM_EPOCHS,\n",
    "                   iter_per_epoch=len(train_loader),\n",
    "                   results_dir=None,\n",
    "                   averaging_iterations=20)\n",
    "plt.show()\n",
    "\n",
    "plot_accuracy(train_acc_list=train_acc_list,\n",
    "              valid_acc_list=valid_acc_list,\n",
    "              results_dir=None)\n",
    "plt.ylim([80, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# model.train() --> Para entrenar\n",
    "# model.eval() --> en inferencia"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "dropout.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
